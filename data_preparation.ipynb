{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Files Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players = pd.read_csv('data/awards_players.csv')\n",
    "df_coaches = pd.read_csv('data/coaches.csv')\n",
    "df_players_teams = pd.read_csv('data/players_teams.csv')\n",
    "df_players = pd.read_csv('data/players.csv')\n",
    "df_series_post = pd.read_csv('data/series_post.csv')\n",
    "df_teams = pd.read_csv('data/teams.csv')\n",
    "df_teams_post = pd.read_csv('data/teams_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleanup and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop collumns that have null values or that have all the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def drop_columns_with_all_nan(df):\n",
    "    # Step 1: Check for columns with all NaN values\n",
    "    columns_to_drop = []\n",
    "    for col in df.columns:\n",
    "        unique_values = df[col].unique()\n",
    "        if len(unique_values) == 1 or all(pd.isna(x) for x in unique_values):\n",
    "            columns_to_drop.append(col)\n",
    "\n",
    "    # Step 2: Drop identified columns\n",
    "    df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Step 3: Print the identified columns to be dropped\n",
    "    print(columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lgID', 'divID', 'seeded', 'tmORB', 'tmDRB', 'tmTRB', 'opptmORB', 'opptmDRB', 'opptmTRB']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgIDWinner', 'lgIDLoser']\n",
      "0\n",
      "['firstseason', 'lastseason']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "['lgID']\n",
      "0\n",
      "20\n",
      "['lgID']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "drop_columns_with_all_nan(df_teams)\n",
    "print(df_teams.duplicated().sum())\n",
    "df_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_teams_post)\n",
    "print(df_teams_post.duplicated().sum())\n",
    "df_teams_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_series_post)\n",
    "print(df_series_post.duplicated().sum())\n",
    "df_series_post.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players)\n",
    "print(df_players.duplicated().sum())\n",
    "df_players.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_players_teams)\n",
    "print(df_players_teams.duplicated().sum())\n",
    "df_players_teams.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_coaches)\n",
    "print(df_coaches.duplicated().sum())\n",
    "print(df_coaches.duplicated(subset=['tmID', 'year']).sum())\n",
    "df_coaches.drop_duplicates(inplace=True)\n",
    "\n",
    "drop_columns_with_all_nan(df_awards_players)\n",
    "print(df_awards_players.duplicated().sum())\n",
    "df_awards_players.drop_duplicates(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregate data according with previous years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have the information about the year at the end of the playoff in each dataset, to avoid data leakage we will aggregate the data from the two previous years to the current year. And create new datasets by doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_back=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are new teams every year we decided to drop all the collumns as only the teams that played before had any relevant information. So as to not have any bias towards the teams that played before, all collumns were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'N' and 'Y' in the 'playoff' column with 0 and 1\n",
    "\n",
    "df_teams['playoff'] = df_teams['playoff'].map({'N': 0, 'Y': 1})\n",
    "df_teams.sort_values(by=['year', 'tmID'], ascending=[True, True], inplace=True)\n",
    "\n",
    "years = df_teams['year'].unique()\n",
    "teams = df_teams['tmID'].unique()\n",
    "\n",
    "df_teams_copy = df_teams.copy()\n",
    "\n",
    "average_collumns = [\"homeW\",\"homeL\",\"awayW\",\"awayL\",\"confW\",\"confL\",\"min\",\"attend\"]\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'num_playoff_appearances'] = df_teams[(df_teams['year'] >= (year - years_back)) & (df_teams['year'] < year) & (df_teams['tmID'] == team)]['playoff'].sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_first_round_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['firstRound'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_semis_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['semis'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'W').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'total_finals_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['finals'] == 'L').sum()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_won'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['won']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'mean_lost'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['lost']).mean()\n",
    "        df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), 'rank'] = (df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)]['rank']).mean()\n",
    "        for column in average_collumns:\n",
    "            df_teams_copy.loc[(df_teams_copy['year'] == year) & (df_teams_copy['tmID'] == team), column] = df_teams[(df_teams['year'] >= (year - years_back)) &(df_teams['year'] < year) & (df_teams['tmID'] == team)][column].mean()\n",
    " \n",
    "         \n",
    "df_teams_copy.drop(columns=['firstRound', 'semis', 'finals',\"won\",\"lost\", 'franchID', 'name', 'arena', \"o_fgm\",\"o_fga\",\"o_ftm\",\"o_fta\",\"o_3pm\",\"o_3pa\",\"o_oreb\",\"o_dreb\",\"o_reb\",\"o_asts\",\"o_pf\",\"o_stl\",\"o_to\",\"o_blk\",\"o_pts\",\"d_fgm\",\"d_fga\",\"d_ftm\",\"d_fta\",\"d_3pm\",\"d_3pa\",\"d_oreb\",\"d_dreb\",\"d_reb\",\"d_asts\",\"d_pf\",\"d_stl\",\"d_to\",\"d_blk\",\"d_pts\",\"GP\"], inplace=True)\n",
    "df_teams_copy.fillna(0, inplace=True)   \n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "categorical_features = ['confID']\n",
    "for feature in categorical_features:\n",
    "    onehotarray = encoder.fit_transform(df_teams_copy[[feature]]).toarray()\n",
    "    items = [f'{feature}_{item}' for item in encoder.categories_[0]]\n",
    "    df_teams_copy[items] = onehotarray\n",
    "df_teams_copy=df_teams_copy.drop(categorical_features, axis=1)\n",
    "\n",
    "df_teams_copy.to_csv('data/teams_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teams post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams_post_copy = pd.DataFrame(columns=[\"year\", \"tmID\", \"W\", \"L\"])\n",
    "sum_collumns = [\"W\", \"L\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        for column in sum_collumns:\n",
    "            w=df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].mean()\n",
    "            l=df_teams_post[(df_teams_post['year'] >= (year - years_back)) &(df_teams_post['year'] < year) & (df_teams_post['tmID'] == team)][column].mean()\n",
    "            new_row = {'year':year, 'tmID':team, column:w}\n",
    "            df_teams_post_copy = pd.concat([df_teams_post_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "df_teams_post_copy.fillna(0, inplace=True)\n",
    "df_teams_post_copy.to_csv('data/teams_post_processed.csv', index=False)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### series post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each team some the number of win and losses they had in the year. For each year we then agregate the information from the previous two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "winning_team_stats = df_series_post.groupby([\"year\", \"tmIDWinner\"])[[\"W\"]].sum().reset_index()\n",
    "winning_team_stats.columns = [\"year\", \"tmID\", \"total_wins\"]\n",
    "\n",
    "losing_team_stats = df_series_post.groupby([\"year\", \"tmIDLoser\"])[[\"L\"]].sum().reset_index()\n",
    "losing_team_stats.columns = [\"year\", \"tmID\", \"total_losses\"]\n",
    "\n",
    "# Merge the winning and losing team statistics\n",
    "team_stats = winning_team_stats.merge(losing_team_stats, on=[\"year\", \"tmID\"], how=\"outer\").fillna(0)\n",
    "team_stats_copy = pd.DataFrame(columns=[\"year\", \"tmID\", \"total_wins\", \"total_losses\"])\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        total_wins = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)]['total_wins'].mean()\n",
    "        total_losses = team_stats[(team_stats['year'] >= (year - years_back)) &(team_stats['year'] < year) & (team_stats['tmID'] == team)]['total_losses'].mean()\n",
    "        new_row = {'year': year, 'tmID': team, 'total_wins': total_wins, 'total_losses': total_losses}\n",
    "        team_stats_copy = pd.concat([team_stats_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "team_stats_copy.fillna(0, inplace=True)\n",
    "team_stats_copy.to_csv('data/series_post_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In basketball, one can calculate the total points scored using the following formula:\n",
    "Total Points = Free Throws Made (ftMade) + 2 * (Field Goals Made (fgMade) - Three-Pointers Made (threeMade)) + 3 * Three-Pointers Made (threeMade).\n",
    "However, it's important to note that the given dataset already includes a dedicated column for total points. Consequently, the columns for Free Throws Made (ftMade), Field Goals Made (fgMade), and Three-Pointers Made (threeMade)  end up giving redundant information, and therefore, are not useful and can be deleted from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_players_teams['Postperformance'] = (df_players_teams['PostPoints'] + df_players_teams['PostRebounds'] +\n",
    "                           df_players_teams['PostAssists'] + df_players_teams['PostSteals'] +\n",
    "                           df_players_teams['PostBlocks']) - (df_players_teams['PostTurnovers'] +\n",
    "                           df_players_teams['PostPF'])   \n",
    "df_players_teams['performance'] = (df_players_teams['points'] + df_players_teams['rebounds'] +\n",
    "                           df_players_teams['assists'] + df_players_teams['steals'] +\n",
    "                           df_players_teams['blocks']) - (df_players_teams['turnovers'] +\n",
    "                           df_players_teams['PF'])   \n",
    "points_made = 1 * df_players_teams['ftMade'] + 2 * (df_players_teams['fgMade'] - df_players_teams['threeMade']) + 3 * df_players_teams['threeMade']\n",
    "points_attempted = 1 * df_players_teams['ftAttempted'] + 2 * (df_players_teams['fgAttempted'] - df_players_teams['threeAttempted']) + 3 * df_players_teams['threeAttempted']\n",
    "df_players_teams['points_precision'] = points_attempted - points_made\n",
    "\n",
    "post_points_made = 1 * df_players_teams['PostftMade'] + 2 * (df_players_teams['PostfgMade'] - df_players_teams['PostthreeMade']) + 3 * df_players_teams['PostthreeMade']\n",
    "post_points_attempted = 1 * df_players_teams['PostftAttempted'] + 2 * (df_players_teams['PostfgAttempted'] - df_players_teams['PostthreeAttempted']) + 3 * df_players_teams['PostthreeAttempted']\n",
    "df_players_teams['Postpoints_precision'] = post_points_attempted - post_points_made\n",
    "\n",
    "df_players_teams.drop(columns=['points', 'rebounds', 'assists', 'steals', 'blocks', 'turnovers', 'PF', 'PostPoints', 'PostRebounds', 'PostAssists', 'PostSteals', 'PostBlocks', 'PostTurnovers', 'PostPF'], inplace=True)\n",
    "df_players_teams.drop(columns=['ftMade', 'fgMade', 'threeMade', 'fgAttempted', 'ftAttempted', 'threeAttempted', 'PostftMade', 'PostfgMade', 'PostthreeMade', 'PostfgAttempted', 'PostftAttempted', 'PostthreeAttempted'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each player calculate the statistics of the previous two years, independently of the team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1876 entries, 0 to 1875\n",
      "Data columns (total 20 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   playerID              1876 non-null   object\n",
      " 1   year                  1876 non-null   int64 \n",
      " 2   stint                 1876 non-null   int64 \n",
      " 3   tmID                  1876 non-null   object\n",
      " 4   GP                    1876 non-null   int64 \n",
      " 5   GS                    1876 non-null   int64 \n",
      " 6   minutes               1876 non-null   int64 \n",
      " 7   oRebounds             1876 non-null   int64 \n",
      " 8   dRebounds             1876 non-null   int64 \n",
      " 9   dq                    1876 non-null   int64 \n",
      " 10  PostGP                1876 non-null   int64 \n",
      " 11  PostGS                1876 non-null   int64 \n",
      " 12  PostMinutes           1876 non-null   int64 \n",
      " 13  PostoRebounds         1876 non-null   int64 \n",
      " 14  PostdRebounds         1876 non-null   int64 \n",
      " 15  PostDQ                1876 non-null   int64 \n",
      " 16  Postperformance       1876 non-null   int64 \n",
      " 17  performance           1876 non-null   int64 \n",
      " 18  points_precision      1876 non-null   int64 \n",
      " 19  Postpoints_precision  1876 non-null   int64 \n",
      "dtypes: int64(18), object(2)\n",
      "memory usage: 293.2+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1290 entries, 1 to 1871\n",
      "Data columns (total 19 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   playerID              1290 non-null   object \n",
      " 1   year                  1290 non-null   int64  \n",
      " 2   tmID                  1290 non-null   object \n",
      " 3   GP                    1290 non-null   float64\n",
      " 4   GS                    1290 non-null   float64\n",
      " 5   minutes               1290 non-null   float64\n",
      " 6   oRebounds             1290 non-null   float64\n",
      " 7   dRebounds             1290 non-null   float64\n",
      " 8   dq                    1290 non-null   float64\n",
      " 9   PostGP                1290 non-null   float64\n",
      " 10  PostGS                1290 non-null   float64\n",
      " 11  PostMinutes           1290 non-null   float64\n",
      " 12  PostoRebounds         1290 non-null   float64\n",
      " 13  PostdRebounds         1290 non-null   float64\n",
      " 14  PostDQ                1290 non-null   float64\n",
      " 15  Postperformance       1290 non-null   float64\n",
      " 16  performance           1290 non-null   float64\n",
      " 17  points_precision      1290 non-null   float64\n",
      " 18  Postpoints_precision  1290 non-null   float64\n",
      "dtypes: float64(16), int64(1), object(2)\n",
      "memory usage: 201.6+ KB\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "df_players_teams_copy = df_players_teams.copy()\n",
    "average_collumns = [\"GP\",\"GS\",\"minutes\",\"oRebounds\",\"dRebounds\",\"dq\",\"PostGP\",\"PostGS\",\"PostMinutes\",\"PostoRebounds\",\"PostdRebounds\",\"PostDQ\", 'performance','Postperformance', 'points_precision', 'Postpoints_precision' ]\n",
    "\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        players = df_players_teams[(df_players_teams['year'] == year) & (df_players_teams['tmID'] == team)]['playerID'].unique()\n",
    "        for player in players:\n",
    "            for column in average_collumns:\n",
    "                df_players_teams_copy.loc[(df_players_teams_copy['year'] == year) & (df_players_teams_copy['tmID'] == team) & (df_players_teams_copy['playerID'] == player), column] = df_players_teams[(df_players_teams['year'] >= (year - years_back)) &(df_players_teams['year'] < year)  & (df_players_teams['playerID'] == player)][column].mean()\n",
    "\n",
    "df_players_teams_copy.dropna(inplace=True)\n",
    "df_players_teams_copy.drop(columns=['stint'], inplace=True)\n",
    "df_players_teams_copy.to_csv('data/players_teams_processed.csv', index=False)\n",
    "\n",
    "print(df_players_teams.info(), df_players_teams_copy.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coaches_copy = df_coaches.copy()\n",
    "\n",
    "average_collumns = [\"won\",\"lost\",\"post_wins\",\"post_losses\"]\n",
    "for year in years:\n",
    "    for team in teams:\n",
    "        coaches= df_coaches[(df_coaches['year'] == year) & (df_coaches['tmID'] == team)]['coachID'].unique()\n",
    "        for coach in coaches:\n",
    "            for column in average_collumns:\n",
    "                df_coaches_copy.loc[(df_coaches_copy['year'] == year) & (df_coaches_copy['tmID'] == team) & (df_coaches_copy['coachID'] == coach), column] = df_coaches[(df_coaches['year'] >= (year - years_back)) &(df_coaches['year'] < year) & (df_coaches['coachID'] == coach)][column].mean()         \n",
    "\n",
    "df_coaches_copy.fillna(0, inplace=True)\n",
    "df_coaches_copy.to_csv('data/coaches_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeOutliersMean(data, column):\n",
    "    #change the outliers with the mean\n",
    "    #SFinding the IQR\n",
    "    percentile25 = data[column].quantile(0.25)\n",
    "    percentile75 = data[column].quantile(0.75)\n",
    "    #Finding the upper and lower limits\n",
    "    iqr = percentile75 - percentile25\n",
    "    upper_limit = percentile75 + 1.5 * iqr\n",
    "    lower_limit = percentile25 - 1.5 * iqr\n",
    "\n",
    "    # Find outliers\n",
    "    outliers = data[(data[column] > upper_limit) | (data[column] < lower_limit)]\n",
    "\n",
    "    # Replace outliers with the mean of the 'height' column\n",
    "    mean_height = data[column].mean()\n",
    "    data.loc[outliers.index, column] = mean_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop players from whom we have no information and chabge the outliers to the mean of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_players = df_players[~((df_players['pos'].isna()) &\n",
    "                            (df_players['height'] == 0.0) &\n",
    "                            (df_players['weight'] == 0) &\n",
    "                            (df_players['college'].isna()) &\n",
    "                            (df_players['collegeOther'].isna()) &\n",
    "                            (df_players['birthDate'] == \"0000-00-00\") &\n",
    "                            (df_players['deathDate'] == \"0000-00-00\"))]\n",
    "changeOutliersMean(df_players, 'height')\n",
    "changeOutliersMean(df_players, 'weight')\n",
    "df_players.to_csv('data/players_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign different weights to the awards according to the importance of the award.\n",
    "- Kim Perrot Sportsmanship Award: 0\n",
    "- Most Valuable Player: 2\n",
    "- The rest 1\n",
    "Then calculate the number of awards for each player in the previous two years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awards_players['award_value'] = 1\n",
    "# Assign a weight of 2 to awards related to \"Kim Perrot Sportsmanship\"\n",
    "df_awards_players.loc[df_awards_players['award'].str.contains('Kim Perrot Sportsmanship'), 'award_value'] = 0\n",
    "df_awards_players.loc[df_awards_players['award'].str.contains('Kim Perrot Sportsmanship Award'), 'award_value'] = 0\n",
    "\n",
    "# Assign a weight of 1 to awards related to \"WNBA Finals Most Valuable Player\" and \"All-Star Game Most Valuable Player\"\n",
    "df_awards_players.loc[df_awards_players['award'].isin(['WNBA Finals Most Valuable Player', 'All-Star Game Most Valuable Player', 'Most Valuable Player']), 'award_value'] = 2\n",
    "# Print the updated DataFrame\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "award_counts_copy = pd.DataFrame(columns=[\"year\", \"playerID\", \"award_count\"])\n",
    "players = df_awards_players['playerID'].unique()\n",
    "# Iterate over all possible combinations of \"year\" and \"player\" and add them to the DataFrame\n",
    "for year in years:\n",
    "    for player in players:\n",
    "        award_count = df_awards_players[(df_awards_players['year'] >= (year - years_back)) & (df_awards_players['year'] < year) & (df_awards_players['playerID'] == player)]['award_value'].sum()\n",
    "        new_row = {\"year\": year, \"playerID\": player, \"award_count\": award_count}\n",
    "        award_counts_copy = pd.concat([award_counts_copy, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "award_counts_copy.dropna(inplace=True)\n",
    "award_counts_copy.to_csv('data/awards_players_processed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
